import com.att.nccicd.config.conf as config
conf = new config(env).CONF

LOCI_REPO = 'https://git.openstack.org/openstack/loci.git'

LOCAL_WEB_PORT = '8080'
LOCAL_WEB_URL = "http://172.18.0.1:${LOCAL_WEB_PORT}"

PROJECT = JOB_BASE_NAME
SEMANTIC_RELEASE_VERSION = "0.9.0"

ARTF_REPO = 'openstack'
if (env.GERRIT_EVENT_TYPE == 'patchset-created' ||
    env.GERRIT_EVENT_TYPE == 'comment-added') {
    ARTF_REPO += '-patchset'
}

if (PROJECT == "mos-neutron-sriov" || PROJECT == "mos-nova-1804") {
    LOCI_BASE_IMAGE = conf.LOCI_SRIOV_BASE_IMAGE
} else {
    LOCI_BASE_IMAGE = conf.LOCI_BASE_IMAGE
}

if (env.GERRIT_REFSPEC) {
    PROJECT_REF = GERRIT_REFSPEC
    PROJECT_VERSION = GERRIT_PATCHSET_REVISION
    PROJECT_BRANCH = GERRIT_BRANCH
    DISPLAY_PREFIX = GERRIT_EVENT_TYPE
    PROJECT_URL = GERRIT_CHANGE_URL
} else {
    PROJECT_VERSION = ""
    // need to update url
    PROJECT_URL = ""
    DISPLAY_PREFIX = "manual"
}

currentBuild.displayName = "#${BUILD_NUMBER} ${DISPLAY_PREFIX} ${PROJECT_BRANCH}"

if (PROJECT_BRANCH == 'master') {
    PROJECT_RELEASE = 'ocata'
}

REQ_PROJECT_NAME = 'mos-requirements'
PROJECT_PREFIX = "loci/mos"
PROJECT_SUFFIX = PROJECT.split('-')[1]
PROJECT_REPO = getProjectRepoUrl(PROJECT)
WHEELS_LATEST = env.REQUIREMENTS_LOCI_IMAGE.trim() ? env.REQUIREMENTS_LOCI_IMAGE : conf.MOS_REQUIREMENTS_LOCI
IMAGE_BASE = "${ARTF_SECURE_DOCKER_URL}/${ARTF_REPO}/${PROJECT_RELEASE}/${PROJECT_PREFIX}"
DEFAULT_ARGS = [
  'FROM':         "${LOCI_BASE_IMAGE}",
  'PROJECT':      "${PROJECT_SUFFIX}",
  'PROJECT_REF':  "${PROJECT_REF}",
  'NO_PROXY':     "${NO_PROXY}",
  'http_proxy':   "${HTTP_PROXY}",
  'https_proxy':  "${HTTPS_PROXY}",
  'PROJECT_REPO': getProjectRepoInternalUrl(PROJECT),
]

// cmd for running Docker in Docker
DIND_CONTAINER = "locibuildcont"
DIND = "sudo docker exec ${DIND_CONTAINER}"

// Compile ssh-agent key names and ssh config from SSH_DATA to be used
// for fetching projects to internal mirror
(KEY_NAMES, SSH_CONFIG) = compileSshData()

def getProjectRepoUrl(prj) {
    return prj.contains("ssh://") ? prj : "${INTERNAL_GERRIT_SSH}/${prj}"
}

def getProjectRepoInternalUrl(prj) {
    return "${LOCAL_WEB_URL}/repo/${prj}"
}

def create_mirrors(projectList, keyList) {
    sshagent(keyList) {
        dir ('web/repo') {
            projectList.each {
                (url, name) = [getProjectRepoUrl(it), it.split("/")[-1]]
                sh "git clone --mirror ${url} ${name}"
                sh "git --git-dir ${name} update-server-info"
            }
        }
    }
}

def getRequirementsImageVersion() {
    sh "${DIND} docker pull ${WHEELS_LATEST}"
    cmd="${DIND} docker inspect --format='{{index .Config.Labels \"org.label-schema.vcs-ref\"}}' ${WHEELS_LATEST}"
    return sh(returnStdout: true, script: cmd).trim()
}

// Prepare local mirrors for project and it's dependencies specified in upper-constraints.txt
// of mos-requirements project. In case of mos-requirements image building, replaces
// external 'git+ssh://' urls in upper-constraints.txt to point local nginx.
// Another solution here could be to maintain separate list of projects to mirror,
// that would simplify current code, but having single source of truth is tempting
def prepare_local_mirrors = {
    // Create ssh config on slave to control what login is used for what resource
    sh "cat <<EOT >> ${HOME}/.ssh/config\n${SSH_CONFIG}EOT"
    projectList = [PROJECT]
    // We always need requirements project as upper-constraints.txt is a single source of truth of a dependeny list
    if (!PROJECT.contains('requirements')) {
        projectList.add(REQ_PROJECT_NAME)
    }
    sh 'mkdir -p web/repo'
    create_mirrors(projectList, [INTERNAL_GERRIT_KEY])
    sh 'mkdir -p worktree'
    gitArg = "--git-dir web/repo/${REQ_PROJECT_NAME} --work-tree worktree"
    // Pick ref for requirements project from requirements image we build current image with
    requirementsRef = PROJECT.contains('requirements') ? PROJECT_REF : getRequirementsImageVersion()
    sh "git ${gitArg} checkout ${requirementsRef}"
    // Creating a list of dependency urls from upper-constraints.txt
    dependencyList = []
    uc_path = 'worktree/upper-constraints.txt'
    upperConstraints = readFile uc_path
    (upperConstraints =~ /git\+(ssh:\/\/.*?\/.*?)@.*/).each {
        dependencyList.add(it[1])
    }
    // if we build requirements image, replace external urls to point nginx in
    // upper-constraints.txt and replace PROJECT_REF build argument
    if (dependencyList && PROJECT.contains('requirements')) {
        upperConstraints = upperConstraints.replaceAll("((?<=git\\+)ssh://.*(?=/.+@))", "${LOCAL_WEB_URL}/repo")
        writeFile file: uc_path, text: upperConstraints
        sh "git ${gitArg} diff"
        sh "git ${gitArg} checkout -b local"
        sh "git ${gitArg} -c 'user.name=Jenkins' -c 'user.email=jenkins@example.com' commit -a -m \"Switch to local urls\""
        sh "git ${gitArg} update-server-info"
        DEFAULT_ARGS['PROJECT_REF'] = 'local'
    }
    create_mirrors(dependencyList, KEY_NAMES)
}

def compileSshData() {
    sshConfig = ""
    keys = []
    parseSshData().each { entry ->
        sshConfig += "Host $entry.value.resource\n" +
                     "User $entry.value.user\n"
        keys.add(entry.key)
    }
    return [keys, sshConfig]
}

// Parse json containing {'<credential_name>': {'user': '<user>', 'resource': '<resource>'}}, ...}
// The source of data what credentials to use in ssh-agent with what user to what resource
def parseSshData() {
    return new groovy.json.JsonSlurper().parseText(SSH_DATA)
}

def buildLociMos(projConfArgs = null, wheelArgs = null) {

    sh "${DIND} docker pull ${LOCI_BASE_IMAGE}"
    def cmd="${DIND} docker inspect --format='{{index .RepoDigests 0}}' ${LOCI_BASE_IMAGE}"
    def base_sha256 = sh(returnStdout: true, script: cmd).trim()

    def loci_version = gerrit.getVersion(LOCI_REPO, "master")

    LOCI_REPO_PATH = "/tmp/loci"
    // Clone loci repo to apply cicd patch for tests deletion
    sh "${DIND} git clone ${LOCI_REPO} ${LOCI_REPO_PATH}"

    // Copy script for tests cleanup to docker
    data = libraryResource "cicd/remove_tests.sh"
    writeFile file: 'remove_tests.sh', text: data

    sh "sudo docker exec -e REMOVE_TESTS_FILE_DATA=\"\$(cat ${WORKSPACE}/remove_tests.sh)\" ${DIND_CONTAINER} sh -c 'echo \"\$REMOVE_TESTS_FILE_DATA\" > ${LOCI_REPO_PATH}/scripts/remove_tests.sh'"
    sh "${DIND} chmod +x ${LOCI_REPO_PATH}/scripts/remove_tests.sh"

    // Add tests deletion step into install scenario for loci
    sh "${DIND} sed  -i '/clone_project.sh/a \$(dirname \$0)/remove_tests.sh' ${LOCI_REPO_PATH}/scripts/install.sh"

    def labels = " --label org.label-schema.vcs-ref=${PROJECT_VERSION}\
      --label org.label-schema.vcs-url=${PROJECT_URL}\
      --label org.label-schema.loci-ref=${loci_version}\
      --label org.label-schema.base-image=${base_sha256}\
      --label org.label-schema.vendor=\"${conf.CUSTOM_LABEL}\"\
      --label org.label-schema.version=${SEMANTIC_RELEASE_VERSION}.${BUILD_NUMBER}"

    if (!PROJECT.contains('requirements')) {
        sh "${DIND} docker pull ${WHEELS_LATEST}"
        cmd="${DIND} docker inspect --format='{{index .RepoDigests 0}}' ${WHEELS_LATEST}"
        def requirements_sha256 = sh(returnStdout: true, script: cmd).trim()
        labels += " --label org.label-schema.requirements-image=${requirements_sha256}"
    }

    if (env.GERRIT_EVENT_TYPE == 'change-merged') {
       labels += " --label org.label-schema.vcs-event=${GERRIT_EVENT_TYPE}"
    }

    def argsMap = loci.mergeArgs([DEFAULT_ARGS, projConfArgs, wheelArgs])
    def args = loci.buildParameters(argsMap)
    def image_tag = "${IMAGE_BASE}/${PROJECT}:${PROJECT_VERSION}.${BUILD_TIMESTAMP}"
    ansiColor('xterm') {
        sh "${DIND} docker build --force-rm --no-cache ${LOCI_REPO_PATH} ${args} ${labels} --tag ${image_tag}"
    }
    sh "${DIND} docker push ${image_tag}"

    //publish latest (branch) tag on merge for requirements
    if (PROJECT.contains('requirements') && env.GERRIT_EVENT_TYPE == 'change-merged') {
        def image_latest = "${IMAGE_BASE}/${PROJECT}:latest"
        sh "${DIND} docker tag ${image_tag} ${image_latest}"
        sh "${DIND} docker push ${image_latest}"
    }

    return image_tag
}

vm2('loci-bootstrap.sh',
         'cicd-ubuntu-16.04-server-cloudimg-amd64',
         'm1.medium',
         '',
         'loci',
         false){

    stage('Docker Setup') {
        loci.runDind(ARTF_SECURE_DOCKER_URL, "jenkins-artifactory", DIND_CONTAINER)
    }

    stage('Local Repo Setup') {
        loci.runNginx(DIND_CONTAINER, LOCAL_WEB_PORT)
        prepare_local_mirrors()
        if (!env.GERRIT_REFSPEC) {
            PROJECT_VERSION = gerrit.getVersion(PROJECT_REPO, PROJECT_REF, INTERNAL_GERRIT_KEY)
        }
    }

    stage ("Build Project") {
        print "Building ${PROJECT.capitalize()}"
        if (PROJECT.contains('requirements')) {
            IMAGE_LOCI = buildLociMos()
        } else {
            loci.exportWheels(DIND_CONTAINER, WHEELS_LATEST)
            WHEELS_ARG = ['WHEELS': "${LOCAL_WEB_URL}/images/wheels.tar"]
            IMAGE_LOCI = buildLociMos(loci.getDependencies(PROJECT_SUFFIX), WHEELS_ARG)
        }
        LOCI_IMAGE_VAR = "${PROJECT_SUFFIX.toUpperCase()}_LOCI"
        cmd = "${DIND} docker inspect --format='{{index .RepoDigests 0}}' ${IMAGE_LOCI}"
        IMAGE_SHA = sh(returnStdout: true, script: cmd).trim()
        sh "mkdir -p ${WORKSPACE}/artifacts"
        sh "echo $IMAGE_SHA | tee -a ${WORKSPACE}/artifacts/loci_image.txt"
        archiveArtifacts 'artifacts/*'
    }
}

// deploy OSH only for ocata release
if (!PROJECT.contains('requirements') && PROJECT_RELEASE == 'ocata') {

    // OSH AIO requires min 8 cpus cores and 16 GB ram
    vm2('bootstrap.sh',
        'cicd-ubuntu-16.04-server-cloudimg-amd64',
        'm1.xlarge',
        'deploy-osh-aio',
        'basic',
        false) {

        stage('Setup proxy') {
            vm2.setproxy()
        }
        stage('Install docker-ce') {
            osh.installDockerCE()
        }
        stage('Authenticate docker repo') {
            osh.dockerAuth()
        }
        stage('Clone OpenstackHelm') {
            osh.cloneOSH()
        }
        stage('Update OSH proxy') {
            osh.updateProxy()
        }
        stage('Override images') {
            // pass ps image as a map
            print "Overriding default for $LOCI_IMAGE_VAR with $IMAGE_LOCI..."
            osh.imageOverrides(["$LOCI_IMAGE_VAR": "$IMAGE_LOCI"], true)
        }
        stage('Install OSH AIO') {
            try {
                withEnv(['OS_REGION_NAME=',
                  'OS_USERNAME=',
                  'OS_PASSWORD=',
                  'OS_PROJECT_NAME=',
                  'OS_PROJECT_DOMAIN_NAME=',
                  'OS_USER_DOMAIN_NAME=',
                  'OS_AUTH_URL=',
                  "OSH_EXTRA_HELM_ARGS=--values=./tools/overrides/releases/ocata/loci.yaml"]) {
                    osh.installOSHAIO()
                }
            } catch (Exception exception) {
                osh.artifactLogs()
                error "OSH AIO deployment failed with exception $exception"
            }
        }
        stage('Get openstack versions') {
            // pass ps image as a map
            osh.serviceVersions(["$LOCI_IMAGE_VAR": "$IMAGE_LOCI"], true)
        }
        stage('Run Helm tests') {
            osh.runHelmTests()
        }
        stage('Parse test logs for failures') {
            status = osh.parseTestLogs()
            if (status != 0) {
                osh.artifactLogs()
                error "Helm tests failed... see log $WORKSPACE/artifacts/helm_tests.log"
            } else {
                print "Helm tests passed"

                //publish latest (branch) tag on merge
                if (env.GERRIT_EVENT_TYPE == 'change-merged') {
                    print "Promoting $IMAGE_LOCI to latest..."
                    def image_latest = "${IMAGE_BASE}/${PROJECT}:latest"
                    sh "sudo docker tag $IMAGE_LOCI ${image_latest}"
                    sh "sudo docker push ${image_latest}"
                }
            }
        }
    }
}

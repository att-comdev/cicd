import org.yaml.snakeyaml.Yaml
import org.yaml.snakeyaml.DumperOptions;

import groovy.json.JsonSlurperClassic
import groovy.json.JsonOutput


JENKINS_SLAVE_BUILDER = 'genesis-builder'

PROM_BUILD_NODE_NAME = "prom-build"
PROM_BUILD_NODE_IP = '10.24.20.99'
GENESIS_NODE_NAME = "genesis"
GENESIS_NODE_IP = '10.24.20.100'
VMX_NODE_NAME = "vmx"
VMX_NODE_IP = '10.24.20.101'

PROMENADE_IMAGE='quay.io/attcomdev/promenade:master'
ARMADA_IMAGE='quay.io/attcomdev/armada:master'
DRYDOCK_IMAGE='docker.io/sthussey/drydock:386668v14'

MANIFEST_PREFIX='region/atl-lab1'
PROMENADE_CFG="${MANIFEST_PREFIX}/ucp/promenade"
ARMADA_UCP_CFG="${PROMENADE_CFG}/bootstrap-armada-config.yaml"
DRYDOCK_CFG="${MANIFEST_PREFIX}/ucp/drydock.yaml"
ARMADA_OSH_CFG="${MANIFEST_PREFIX}/osh/armada.yaml"

PROM_BUILD_TMPL = "${MANIFEST_PREFIX}/bootstrap/prom-build/prom-build.yaml"
GENESIS_TMPL = "${MANIFEST_PREFIX}/bootstrap/genesis/genesis.yaml"
VMX_TMPL = "${MANIFEST_PREFIX}/bootstrap/vmx/vmx.yaml"

SONOBUOY_CFG="${MANIFEST_PREFIX}/test/sonobuoy.yaml"

ARTF_BASE="ucp/integration/${JOB_BASE_NAME}/${BUILD_NUMBER}"

DECKHAND_URL='http://deckhand-int.ucp.svc.cluster.local:9000/api/v1.0'


def genesis_setup = {
    // genesis.yaml
    checkout poll: false,
        scm: [$class: 'GitSCM',
            branches: [[name: '$CLCP_INTEGRATION_REFSPEC']],
            doGenerateSubmoduleConfigurations: false,
            extensions: [[$class: 'RelativeTargetDirectory',
                relativeTargetDir: 'clcp-integration']],
            submoduleCfg: [],
            userRemoteConfigs: [[refspec: 'refs/changes/*:refs/changes/*',
                url: 'ssh://jenkins-attcomdev@10.24.20.18:29418/clcp-integration',
                    credentialsId:'jenkins-stage-master']]]

    // funcs.groovy
    checkout poll: false,
        scm: [$class: 'GitSCM',
            branches: [[name: '$CICD_GERRIT_REFSPEC']],
            doGenerateSubmoduleConfigurations: false,
            extensions: [[$class: 'RelativeTargetDirectory',
                relativeTargetDir: 'cicd']],
            submoduleCfg: [],
            userRemoteConfigs: [[refspec: 'refs/changes/*:refs/changes/*',
                url: 'https://review.gerrithub.io/att-comdev/cicd']]]

    def funcs = load "${WORKSPACE}/cicd/integration/genesis-integration/funcs.groovy"

    funcs.jenkins_slave_destroy(PROM_BUILD_NODE_NAME)
    funcs.jenkins_slave_launch(PROM_BUILD_NODE_NAME,
        "${WORKSPACE}/clcp-integration/${PROM_BUILD_TMPL}", PROM_BUILD_NODE_IP)

    funcs.jenkins_slave_destroy(GENESIS_NODE_NAME)
    funcs.jenkins_slave_launch(GENESIS_NODE_NAME,
        "${WORKSPACE}/clcp-integration/${GENESIS_TMPL}", GENESIS_NODE_IP)

    // integration gap: enable once vMX is available
    // funcs.jenkins_slave_destroy(VMX_NODE_NAME)
    // funcs.jenkins_slave_launch(VMX_NODE_NAME,
    //    "${WORKSPACE}/clcp-integration/${VMX_TMPL}", VMX_NODE_IP)

    stage("Nodes Geting Ready") {
        timeout (14) {
            node(PROM_BUILD_NODE_NAME) {
                sh 'echo "Welcome $(hostname)"'
            }
            node(GENESIS_NODE_NAME) {
                sh 'echo "Welcome $(hostname)"'
            }
        }
    }
}


//// ipmi utils

def ipmi_power_off = {
    withCredentials([usernamePassword(credentialsId: 'integration-ipmi',
                                      usernameVariable: 'IPMI_USERNAME',
                                      passwordVariable: 'IPMI_PASSWORD')]) {
        for (ip = 11; ip <= 14; ip++) {
            opts = "-I lanplus -H 10.23.104.${ip} -U \$IPMI_USERNAME -P \$IPMI_PASSWORD"
            sh ("ipmitool ${opts} chassis power off")
        }
    }
}


def prom_build_prepare = {
    stage("Build Prepare") {
        checkout poll: false,
            scm: [$class: 'GitSCM',
            branches: [[name: '$CLCP_INTEGRATION_REFSPEC']],
            doGenerateSubmoduleConfigurations: false,
            extensions: [],
            submoduleCfg: [],
            userRemoteConfigs: [[refspec: 'refs/changes/*:refs/changes/*',
                url: 'ssh://jenkins-attcomdev@10.24.20.18:29418/clcp-integration',
                    credentialsId:'jenkins-stage-master']]]

        ipmi_power_off()

        // keys added to drydock config
        sh 'ssh-keygen -f genesis-id_rsa -N ""'
    }
}


//// yaml utils

def dump_opts = {
    // add explicit start (---) to documents
    DumperOptions opts = new DumperOptions();
    opts.setExplicitStart(true);
    return opts
}

def dump_yaml = { cfg ->
    return new Yaml(dump_opts()).dump(cfg);
}

def dump_yaml_all = { cfg ->
    return new Yaml(dump_opts()).dumpAll(cfg.iterator());
}


def index_seek = { cfg, val ->
    def index = -1;
    cfg.eachWithIndex { v, i ->
        if (v.metadata.name == val) {
            index = i
            return true // index found
        }
    }
    return index
}


def site_config_overrides = {
    stage("Config Overrides") {

        //// prmenade genesis config

        def promcfg = readYaml file: "${PROMENADE_CFG}/genesis-config.yaml"
        promcfg.data.images.armada = ARMADA_IMAGE

        writeFile file: "${PROMENADE_CFG}/genesis-config.yaml", text: dump_yaml(promcfg)


        //// armada bootstrap

        def armcfg = readYaml file: "${ARMADA_UCP_CFG}"

        def i = index_seek(armcfg, 'drydock')
        armcfg[i].data.values.images.tags.drydock = DRYDOCK_IMAGE
        armcfg[i].data.values.images.tags.drydock_db_sync = DRYDOCK_IMAGE

        i = index_seek(armcfg, 'armada')
        armcfg[i].data.values.images.tags.api = ARMADA_IMAGE

        i = index_seek(armcfg, 'promenade')
        armcfg[i].data.values.images.tags.api = PROMENADE_IMAGE

        writeFile file: "${ARMADA_UCP_CFG}", text: dump_yaml_all(armcfg)


        //// drydock site config

        def drycfg = readYaml file: "${DRYDOCK_CFG}"

        def pkey = readFile (file: "genesis-id_rsa.pub")
        def keys = drycfg[0].data.authorized_keys
        keys.add(pkey)
        drycfg[0].data.authorized_keys = keys

        writeFile file: "${DRYDOCK_CFG}", text: dump_yaml_all(drycfg)
    }
}


//// artf utils

def artf = Artifactory.server 'artifactory'

def artf_spec = { pattern, target ->
    spec = ['files': [['pattern': pattern,
                       'target': target,
                       'flat': true]]]
    return new JsonOutput().toJson(spec)
}

def artf_publish = { pattern, target ->
    info = artf.upload(artf_spec(pattern, target))
    artf.publishBuildInfo(info)
}

def artf_download = { pattern, target ->
    artf.download(artf_spec(pattern, target))
}


def site_config_publish = {
    stage('Site Config Publish') {
        sh "tar czf site-config.tar.gz ${MANIFEST_PREFIX}"
        artf_publish('site-config.tar.gz', "${ARTF_BASE}/configs/")
    }
}


def prom_config_gen = {
    stage ("Promenade Config Gen") {
        opts = '--rm -t -w /target -v $(pwd):/target'
        cmd = "promenade generate-certs -o ${PROMENADE_CFG}/ ${PROMENADE_CFG}/*.yaml"
        sh "sudo docker run ${opts} ${PROMENADE_IMAGE} ${cmd}"

        sh "mkdir -p promenade-bundle"
        cmd = "promenade build-all --validators -o promenade-bundle ${PROMENADE_CFG}/*.yaml"
        sh "sudo docker run ${opts} ${PROMENADE_IMAGE} ${cmd}"
    }
}


def prom_config_publish = {
    stage ("Promenade Config Publish") {
        sh 'tar czf promenade-bundle.tar.gz promenade-bundle'
        artf_publish('promenade-bundle.tar.gz', "${ARTF_BASE}/configs/")
    }
}


def prom_deploy = {
    stage ("Promenade Deploy k8s") {

        artf_download("${ARTF_BASE}/configs/promenade-bundle.tar.gz", "")
        sh "tar xzf promenade-bundle.tar.gz"

        dir ("promenade-bundle") {
            timeout (30) {
                sh "sudo bash genesis.sh"
                sh "sudo bash validate-genesis.sh"
            }
        }
        sh "sudo kubectl get pods --all-namespaces -o wide"
    }
}


//// drydock utils

def drydock_cmd_run = { cmd ->

    drydock_env = "-e OS_USERNAME=drydock" +
        " -e OS_PASSWORD=password" +
        " -e OS_AUTH_URL=http://keystone-api.ucp.svc.cluster.local:80/v3" +
        " -e OS_PROJECT_NAME=service" +
        " -e OS_PROJECT_DOMAIN_NAME=default" +
        " -e OS_USER_DOMAIN_NAME=default" +
        " -e DD_URL=http://drydock-api.ucp.svc.cluster.local:9000" +
        " -e LC_ALL=C.UTF-8" +
        " -e LANG=C.UTF-8"

    drydock_opts = "-v \$(pwd):/target --rm -t --net=host --entrypoint \"drydock\""
    drydock_cmd = "sudo docker run ${drydock_opts} ${drydock_env} ${DRYDOCK_IMAGE}"

    def result = ""

    // todo: keep retry, but report failed calls
    // drydock fails to get status at times
    // looks as issue related to bootactions
    timeout(2) {
        while (!result) {
            try {
                result = sh(returnStdout: true, script: "${drydock_cmd} ${cmd}")
                break
            } catch (error){
                print "Failed to execute ${cmd}: ${error}"
                sleep 20
            }
        }
    }

    return new JsonSlurperClassic().parseText(result)
}


def drydock_task_show = { task ->
    return drydock_cmd_run("task show --task-id=${task}")
}


def drydock_task_create = { design, action, interval ->

    task = drydock_cmd_run("task create --design-ref=${design} -a ${action}")

    def status = task.status
    timeout (interval) {
        while (status != 'complete') {
            sleep interval
            r = drydock_task_show(task.task_id)
            status = r.status
            print "task -> status: ${r.status}, action: ${r.action}"
        }
    }

    r = drydock_task_show(task.task_id).result
    print "task -> status: ${r.status}, result: ${r.result}"

    // bug: drydock fails to report proper status
    // only success should be accepted.. fix when code is ready
    if (r.status != 'success'
            && r.status != 'partial_success'
            && r.status != 'incomplete') {
        print "Failed to execute Drydock task ${task}"
        return 1
    }
    return 0
}


def serve_prom_bundle = {
    // feature gap: run nginx for hosting promenade YAMLs
    sh "cp -R ${WORKSPACE}/${MANIFEST_PREFIX}/osh ${WORKSPACE}/promenade-bundle"
    def sp = "${WORKSPACE}/promenade-bundle"
    sh "sudo docker run -d -v ${sp}:/usr/share/nginx/html -p 6880:80 nginx"
}


def keystone_token_get = {

    keystone_image = "kolla/ubuntu-source-keystone:3.0.3"

    docker_env = "-e 'OS_AUTH_URL=http://keystone-api.ucp.svc.cluster.local:80/v3'" +
        " -e 'OS_PROJECT_DOMAIN_NAME=default'" +
        " -e 'OS_USER_DOMAIN_NAME=default'" +
        " -e 'OS_PROJECT_NAME=service'" +
        " -e 'OS_REGION_NAME=RegionOne'" +
        " -e 'OS_USERNAME=drydock'" +
        " -e 'OS_PASSWORD=password'" +
        " -e 'OS_IDENTITY_API_VERSION=3'"

    docker_opts = "--rm --net=host"
    keystone_cmd = "openstack token issue -f value -c id"
    docker_cmd = "sudo docker run ${docker_opts} ${docker_env} ${keystone_image} ${keystone_cmd}"

    return sh(returnStdout: true, script: docker_cmd).trim()
}


//// deckhand utils

def deckhand_load = {
    stage('Deckhand Load') {

        artf_download("${ARTF_BASE}/configs/site-config.tar.gz", "")
        sh "tar xzf site-config.tar.gz"

        def token = keystone_token_get()

        def headers = "-H \"X-AUTH-TOKEN: ${token}\"" +
                  " -H \"Content-Type: application/x-yaml\""
        def opts = "-v -X PUT --data-binary @${DRYDOCK_CFG}"
        def url = "${DECKHAND_URL}/buckets/drydock/documents"

        sh ("curl ${opts} ${headers} ${url}")

        def opts_tag = "-v -X POST"
        def url_tag = "${DECKHAND_URL}/revisions/1/tags/committed"

        sh ("curl ${opts_tag} ${headers} ${url_tag}")
    }
}


//// drydock provisioning

def site_deploy = {


    def design = "deckhand+${DECKHAND_URL}/revisions/1/rendered-documents"

    if (SHIPYARD_ENABLED.toBoolean()) {
        stage ('Shipyard Site Deploy') {
            checkout poll: false,
                scm: [$class: 'GitSCM',
                branches: [[name: 'master']],
                doGenerateSubmoduleConfigurations: false,
                extensions: [[$class: 'RelativeTargetDirectory',
                    relativeTargetDir: 'shipyard']],
                submoduleCfg: [],
                userRemoteConfigs: [[refspec: 'refs/changes/*:refs/changes/*',
                    url: 'https://review.gerrithub.io/att-comdev/shipyard']]]

        dir ("shipyard/tools") {
            sh "bash deploy_site.sh"
        }
    }
}
    else {
        timeout (14) {
            stage ("Drydock (verify_site)") {
                while(drydock_task_create (design, 'verify_site', 10)) {
                    print 'Still waiting on MaaS import'
                    sleep 60
            }
        }
    }

    da = ['prepare_site', 'prepare_nodes', 'deploy_nodes']
    da.each {
        stage ("Drydock (${it})") {
           if (drydock_task_create (design, it, 40)) {
               sh "exit 1"
           }
        }
    }

//// k8s utils
    // feature gap: eventually promjoin will report back to drydock
    // wait for expected k8s nodes to be ready
    stage ("Nodes Join (promjoin)") {
        timeout(14) {
            while(true) {
                nodes = ['genesis', 'controller01', 'controller02', 'worker01', 'worker02']
                def ready = true
                nodes.find {
                    cmd = "sudo kubectl get nodes |grep ' Ready' |grep ${it}"
                    if (sh(returnStatus:true, script: cmd)) {
                        print "Kubernetes node ${it} not ready yet"
                        ready = false
                        return true // stop at first
                    }
                }
                if (ready) break
                sleep 60
            }
        }
    }
    dir ("promenade-bundle") {
        sleep 120 // investigate: need to wait
        sh "sudo bash validate-cluster.sh"
    }

    sh "sudo kubectl get pods --all-namespaces -o wide"


//// armada install openstack

    stage ("Armada Apply") {

        // todo: this will go away in latest armada
            sh 'sudo mkdir -p ~/.kube'
            sh 'sudo chown -R ubuntu:ubuntu ~/.kube'
            sh 'cp -r /etc/kubernetes/admin/pki ~/.kube/pki'
            sh 'cat /etc/kubernetes/admin/kubeconfig.yaml | sed -e \'s/\\/etc\\/kubernetes\\/admin/./\' > ~/.kube/config'

            def get = "sudo kubectl get pods -n ucp -o wide | grep tiller-deploy | awk '{print \$6 }'"
            tiller = sh(script: get, returnStdout: true).trim()
            armada_cmd = "apply /target/${ARMADA_OSH_CFG} --tiller-host=${tiller} --tiller-port=44134"
            docker_opts = "-t -v ~/.kube:/armada/.kube -v \$(pwd):/target --net=host"
            sh "sudo docker run ${docker_opts} ${ARMADA_IMAGE} ${armada_cmd}"
        }
    }
}


def sonobuoy_run = {
    if (SONOBUOY_ENABLED.toBoolean()) {
        stage('Sonobuoy E2E (v0.9.0)') {
            sh 'mkdir -p /tmp/sonobuoy' // test results

            sh "cat ${SONOBUOY_CFG} |sudo kubectl apply -f -"

            timeout (12) {
                cmd = 'sudo kubectl get pods -n heptio-sonobuoy |grep 1/1'
                while (sh(returnStatus: true, script: cmd)) sleep 30
            }

            timeout (120) {
                cmd = 'sudo kubectl get pods -n heptio-sonobuoy |grep 1/1'
                while (!sh(returnStatus: true, script: cmd)) sleep 300
            }
        }

        stage('Sonobuoy Publish') {

            artf_publish('/tmp/sonobuoy/*.tar.gz', "${ARTF_BASE}/sonobuoy/")

            sh 'mkdir -p results'
            sh 'tar xf /tmp/sonobuoy/*.tar.gz -C results'

            junit 'results/plugins/e2e/results/junit_01.xml'
        }
    }
}


def console_logs_publish = {
    stage('Build Log Publish') {

        sh "wget -q ${BUILD_URL}/consoleText"
        sh 'tar czf consoleText.tar.gz consoleText'

        artf_publish('consoleText.tar.gz', "${ARTF_BASE}/logs/")
    }
}



//// main flow

node(JENKINS_SLAVE_BUILDER) {
    genesis_setup()
}

node(PROM_BUILD_NODE_NAME) {
    prom_build_prepare()

    site_config_overrides()
    site_config_publish()

    prom_config_gen()
    prom_config_publish()
}

node(GENESIS_NODE_NAME) {

    prom_deploy()

    // upload Drydock site YAMLs into Deckhand
    deckhand_load()

    // feature gap: remove when prom supports API
    // serves node join/init scripts over http
    serve_prom_bundle()

    site_deploy()

    // e2e kubernetes conformance tests (optional)
    sonobuoy_run()
}

node(PROM_BUILD_NODE_NAME) {
    console_logs_publish()
}

